{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Objectives\n",
        "After completing this lab you will be able to:\n",
        "\n",
        "Use scikit-learn to build a model to solve a classification problem\n",
        "Implement a pipeline to combine your preprocessing steps with a machine learning model\n",
        "Interpret the results of your modelling\n",
        "Update your pipeline with a different machine learning model\n",
        "Compare the preformances of your classifiers"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install numpy\n",
        "!pip install matplotlib\n",
        "!pip install pandas\n",
        "!pip install scikit-learn\n",
        "!pip install seaborn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "import seaborn as sns\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load the Titanic dataset using Seaborn"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "titanic = sns.load_dataset('titanic')\n",
        "titanic.head()"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Select relevant features and the target"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "titanic.count()"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Features to drop\n",
        "deck has a lot of missing values so we'll drop it. age has quite a few missing values as well. Although it could be, embarked and embark_town don't seem relevant so we'll drop them as well. It's unclear what alive refers to so we'll ignore it."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Target\n",
        "`survived` is our target class variable."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "features = ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'class', 'who', 'adult_male', 'alone']\n",
        "target = 'survived'\n",
        "\n",
        "X = titanic[features]\n",
        "y = titanic[target]"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#How balanced are the classes?\n",
        "y.value_counts()"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So about 38% of the passengers in the data set survived.  \n",
        "Because of this slight imbalance, we should stratify the data when performing train/test split and for cross-validation."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Split the data into training and testing sets"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Define preprocessing transformers for numerical and categorical features\n",
        "**Automatically detect numerical and categorical columns and assign them to separate numeric and categorical features\u00b6**"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_features = X_train.select_dtypes(include=['number']).columns.tolist()\n",
        "categorical_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Define separate preprocessing pipelines for both feature types"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Combine the transformers into a single column transformer\n",
        "We'll use the sklearn \"column transformer\" estimator to separately transform the features, which will then concatenate the output as a single feature space, ready for input to a machine learning estimator."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create a model pipeline\n",
        "Now let's complete the model pipeline by combining the preprocessing with a Random Forest classifier"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', RandomForestClassifier(random_state=42))\n",
        "])"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Define a parameter grid\n",
        "We'll use the grid in a cross validation search to optimize the mode"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'classifier__n_estimators': [50, 100],\n",
        "    'classifier__max_depth': [None, 10, 20],\n",
        "    'classifier__min_samples_split': [2, 5]\n",
        "}"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Perform grid search cross-validation and fit the best model to the training data"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross-validation method\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True)"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train the pipeline model"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "model = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=cv, scoring='accuracy', verbose=2)\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Get the model predictions from the grid search estimator on the unseen data\n",
        "Also print a classification report"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Plot the confusion matrix"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure()\n",
        "sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='d')\n",
        "\n",
        "# Set the title and labels\n",
        "plt.title('Titanic Classification Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "\n",
        "# Show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature importances\n",
        "Let's figure out how to get the feature importances of our overall model. You'll need to know how to do this for your final project.\n",
        "First, to obtain the categorical feature importances, we have to work our way backward through the modelling pipeline to associate the feature importances with their one-hot encoded input features that were transformed from the original categorical features.\n",
        "\n",
        "We don't need to trace back through the pipeline for the numerical features, because we didn't transfrom them into new ones in any way.\n",
        "Remember, we went from categorical features to one-hot encoded features, using the 'cat' column transformer.\n",
        "\n",
        "Here's how you trace back through the trained model to access the one-hot encoded feature names:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "model.best_estimator_['preprocessor'].named_transformers_['cat'].named_steps['onehot'].get_feature_names_out(categorical_features)"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice how the one-hot encoded features are named - for example, sex was split into two boolean features indicating whether the sex is male or female.\n",
        "\n",
        "Now let's get all of the feature importances and associate them with their transformed feature names."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "feature_importances = model.best_estimator_['classifier'].feature_importances_\n",
        "\n",
        "# Combine the numerical and one-hot encoded categorical feature names\n",
        "feature_names = numerical_features + list(model.best_estimator_['preprocessor']\n",
        "                                        .named_transformers_['cat']\n",
        "                                        .named_steps['onehot']\n",
        "                                        .get_feature_names_out(categorical_features))"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Display the feature importances in a bar plot\n",
        "Define a feature importance DataFrame, then plot it"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "importance_df = pd.DataFrame({'Feature': feature_names,\n",
        "                              'Importance': feature_importances\n",
        "                             }).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(importance_df['Feature'], importance_df['Importance'], color='skyblue')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.title('Most Important Features in predicting whether a passenger survived')\n",
        "plt.xlabel('Importance Score')\n",
        "plt.show()\n",
        "\n",
        "# Print test score\n",
        "test_score = model.score(X_test, y_test)\n",
        "print(f\"\\nTest set accuracy: {test_score:.2%}\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The test set accuracy is somewhat satisfactory. However,regarding the feature impoirtances, it's crucially important to realize that there is most likely plenty of dependence amongst these variables, and a more detailed modelling approach including correlation analysis is required to draw proper conclusions. For example, no doubt there is significant information shared by the variables `age`, `sex_male`, and `who_man`"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Try another model"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace RandomForestClassifier with LogisticRegression\n",
        "pipeline.set_params(classifier=LogisticRegression(random_state=42))\n",
        "\n",
        "# update the model's estimator to use the new pipeline\n",
        "model.estimator = pipeline\n",
        "\n",
        "# Define a new grid with Logistic Regression parameters\n",
        "param_grid = {\n",
        "    # 'classifier__n_estimators': [50, 100],\n",
        "    # 'classifier__max_depth': [None, 10, 20],\n",
        "    # 'classifier__min_samples_split': [2, 5],\n",
        "    'classifier__solver' : ['liblinear'],\n",
        "    'classifier__penalty': ['l1', 'l2'],\n",
        "    'classifier__class_weight' : [None, 'balanced']\n",
        "}\n",
        "\n",
        "model.param_grid = param_grid\n",
        "\n",
        "# Fit the updated pipeline with Logistic Regression\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Display the clasification report for the new model and compare the results to your previous model."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "#All of the scores are slightly better for logistic regression than for random forest classification, although the differences are insignificant."
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Display the confusion matrix for the new model and compare the results to your previous model."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure()\n",
        "sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='d')\n",
        "\n",
        "# Set the title and labels\n",
        "plt.title('Titanic Classification Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "\n",
        "# Show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "#Again, the results show a slight improvement, with one more true positive and one more true negative."
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Extract the logistic regression feature coefficients and plot their magnitude in a bar chart.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "coefficients = model.best_estimator_.named_steps['classifier'].coef_[0]\n",
        "\n",
        "# Combine numerical and categorical feature names\n",
        "numerical_feature_names = numerical_features\n",
        "categorical_feature_names = (model.best_estimator_.named_steps['preprocessor']\n",
        "                                     .named_transformers_['cat']\n",
        "                                     .named_steps['onehot']\n",
        "                                     .get_feature_names_out(categorical_features)\n",
        "                            )\n",
        "feature_names = numerical_feature_names + list(categorical_feature_names)"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Plot the feature coefficient magnitudes in a bar chart\u00b6"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame for the coefficients\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Coefficient': coefficients\n",
        "}).sort_values(by='Coefficient', ascending=False, key=abs)  # Sort by absolute values\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(importance_df['Feature'], importance_df['Coefficient'].abs(), color='skyblue')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.title('Feature Coefficient magnitudes for Logistic Regression model')\n",
        "plt.xlabel('Coefficient Magnitude')\n",
        "plt.show()\n",
        "\n",
        "# Print test score\n",
        "test_score = model.best_estimator_.score(X_test, y_test)\n",
        "print(f\"\\nTest set accuracy: {test_score:.2%}\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although the performances of the two models are virtually identical, the features that are important to the two models are very different. This suggests there must be more work to do to better grasp the actual feature importancdes. A smentioned above, it's crucially important to realize that there is most likely plenty of dependence amongst these variables, and a more detailed modelling approach including correlation analysis is required to draw proper conclusions. For example, there is significant information implied between the variables `who_man`, `who_woman`, and `who_child`, because if a person is neither a man nor a woman, then they muct be a child.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {}
    }
  ]
}