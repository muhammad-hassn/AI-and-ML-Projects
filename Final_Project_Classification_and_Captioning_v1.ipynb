{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.19.0 tensorflow-io-gcs-filesystem==0.37.1 transformers==4.45.0 pillow matplotlib requests\n"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(\"\u2705 TensorFlow loaded:\", tf.__version__)\n"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, tarfile, requests\n",
        "\n",
        "url = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/ZjXM4RKxlBK9__ZjHBLl5A/aircraft-damage-dataset-v1.tar'\n",
        "tar_filename = 'aircraft_damage_dataset_v1.tar'\n",
        "extracted_folder = 'aircraft_damage_dataset_v1'\n",
        "\n",
        "if not os.path.exists(extracted_folder):\n",
        "    print(\"\ud83d\udce5 Downloading dataset...\")\n",
        "    r = requests.get(url, stream=True)\n",
        "    with open(tar_filename, \"wb\") as f:\n",
        "        for chunk in r.iter_content(chunk_size=1024):\n",
        "            if chunk:\n",
        "                f.write(chunk)\n",
        "\n",
        "    print(\"\ud83d\udce6 Extracting files...\")\n",
        "    with tarfile.open(tar_filename) as tar:\n",
        "        tar.extractall()\n",
        "    print(\"\u2705 Dataset ready:\", extracted_folder)\n",
        "else:\n",
        "    print(\"\u2705 Dataset already exists.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# -------------------------------\n",
        "# Directories (Update paths if needed)\n",
        "# -------------------------------\n",
        "train_dir = \"aircraft_damage_dataset_v1/train\"\n",
        "valid_dir = \"aircraft_damage_dataset_v1/valid\"\n",
        "test_dir  = \"aircraft_damage_dataset_v1/test\"\n",
        "\n",
        "# Check if directories exist\n",
        "for dir_path in [train_dir, valid_dir, test_dir]:\n",
        "    if not os.path.exists(dir_path):\n",
        "        raise FileNotFoundError(f\"Directory not found: {dir_path}\")\n",
        "\n",
        "# -------------------------------\n",
        "# Data Generators\n",
        "# -------------------------------\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen  = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir, target_size=(224, 224), batch_size=8, class_mode='categorical'\n",
        ")\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    valid_dir, target_size=(224, 224), batch_size=8, class_mode='categorical'\n",
        ")\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir, target_size=(224, 224), batch_size=8, class_mode='categorical'\n",
        ")\n",
        "\n",
        "# -------------------------------\n",
        "# Model Definition (VGG16 Transfer Learning)\n",
        "# -------------------------------\n",
        "base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(224,224,3))\n",
        "\n",
        "# Freeze base model layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Custom classifier on top\n",
        "x = Flatten()(base_model.output)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(2, activation='softmax')(x)  # 2 classes\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# -------------------------------\n",
        "# Model Training\n",
        "# -------------------------------\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=valid_generator,\n",
        "    epochs=3  # Increase as needed\n",
        ")\n",
        "\n",
        "# -------------------------------\n",
        "# Evaluation on Test Data\n",
        "# -------------------------------\n",
        "loss, acc = model.evaluate(test_generator)\n",
        "print(f\"\u2705 Test Accuracy: {acc*100:.2f}%\")\n",
        "\n",
        "# -------------------------------\n",
        "# Plot Training History\n",
        "# -------------------------------\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title(\"Training Accuracy Over Epochs\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "\n",
        "# pick a sample image safely\n",
        "sample_image = test_generator.filepaths[0]  # ensure filepaths exist\n",
        "image = Image.open(sample_image).convert('RGB')\n",
        "\n",
        "inputs = processor(image, return_tensors=\"pt\").to(device)\n",
        "out = model.generate(**inputs)\n",
        "\n",
        "caption = processor.decode(out[0], skip_special_tokens=True)\n",
        "print(\"\ud83d\uddbc\ufe0f Image path:\", sample_image)\n",
        "print(\"\ud83e\udde0 Generated Caption:\", caption)\n"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}